{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "678928d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, losses, metrics, Sequential\n",
    "JSON_PATH = \"../data_rnn/imdb_dataset_prepared.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b929e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a1693a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data from JSON file\n",
    "print(\"Loading data...\")\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "951551b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(data[\"X_train\"], dtype=np.int32)\n",
    "y_train = np.array(data[\"y_train\"], dtype=np.float32)\n",
    "X_test  = np.array(data[\"X_test\"],  dtype=np.int32)\n",
    "y_test  = np.array(data[\"y_test\"],  dtype=np.float32)\n",
    "embeddings = np.array(data[\"embeddings\"], dtype=np.float32)\n",
    "vocab = np.array(data[\"vocab\"])\n",
    "\n",
    "X_train -= 1\n",
    "X_test -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc666457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shift → max index in X_train: 12848 min: 0\n",
      "After shift → max index in X_test:  12848 min: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"After shift → max index in X_train:\", np.max(X_train), \"min:\", np.min(X_train))\n",
    "print(\"After shift → max index in X_test: \", np.max(X_test),  \"min:\", np.min(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5dd9a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embeddings.shape[1]\n",
    "vocab_size = embeddings.shape[0]\n",
    "sequence_length = X_train.shape[1]\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d79c6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (40000, 130)\n",
      "y_train: (40000,)\n",
      "X_test: (10000, 130)\n",
      "y_test: (10000,)\n",
      "embeddings: (12849, 50)\n",
      "vocab: (12849,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(f\"embeddings: {embeddings.shape}\")\n",
    "print(f\"vocab: {vocab.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9e66110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model using Sequential API (simpler approach)\n",
    "model = Sequential([\n",
    "    layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embeddings],\n",
    "        trainable=True\n",
    "    ),\n",
    "    layers.SimpleRNN(\n",
    "        units=16,\n",
    "        activation=\"relu\",\n",
    "        return_sequences=False\n",
    "    ),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "713732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force the model (and therefore each layer) to create its weight tensors:\n",
    "model.build(input_shape=(batch_size, sequence_length))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(),\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9515d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 1/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 45ms/step - accuracy: 0.5098 - loss: 0.6964 - val_accuracy: 0.5039 - val_loss: 0.6936\n",
      "Epoch 2/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.5165 - loss: 0.6915 - val_accuracy: 0.5084 - val_loss: 0.6921\n",
      "Epoch 3/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 43ms/step - accuracy: 0.5246 - loss: 0.6884 - val_accuracy: 0.5307 - val_loss: 0.6832\n",
      "Epoch 4/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 0.5770 - loss: 0.6701 - val_accuracy: 0.6952 - val_loss: 0.5899\n",
      "Epoch 5/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.7099 - loss: 0.5876 - val_accuracy: 0.6928 - val_loss: 0.6073\n",
      "Epoch 6/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.7390 - loss: 0.5590 - val_accuracy: 0.7487 - val_loss: 0.5152\n",
      "Epoch 7/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.7530 - loss: 0.5310 - val_accuracy: 0.7746 - val_loss: 0.4934\n",
      "Epoch 8/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.7773 - loss: 0.5110 - val_accuracy: 0.7798 - val_loss: 0.4946\n",
      "Epoch 9/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 0.7890 - loss: 0.4973 - val_accuracy: 0.7976 - val_loss: 0.4639\n",
      "Epoch 10/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.8030 - loss: 0.4690 - val_accuracy: 0.7956 - val_loss: 0.4698\n",
      "Epoch 11/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.8091 - loss: 0.4570 - val_accuracy: 0.8094 - val_loss: 0.4431\n",
      "Epoch 12/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 42ms/step - accuracy: 0.8180 - loss: 0.4413 - val_accuracy: 0.8038 - val_loss: 0.4593\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 12\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Simple training with model.fit()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True,\n",
    "    verbose=1  # This will print progress for each epoch\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3487e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (151.46s)\tTrain: (l: 0.46, a: 0.82)\tTest:  (l: 0.46, a: 0.81)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 13:56:07.074152: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 (135.90s)\tTrain: (l: 0.44, a: 0.83)\tTest:  (l: 0.45, a: 0.82)\n",
      "Epoch: 3 (140.02s)\tTrain: (l: 0.41, a: 0.84)\tTest:  (l: 0.44, a: 0.82)\n",
      "Epoch: 4 (131.73s)\tTrain: (l: 0.41, a: 0.84)\tTest:  (l: 0.43, a: 0.83)\n",
      "Epoch: 5 (130.65s)\tTrain: (l: 0.40, a: 0.85)\tTest:  (l: 0.42, a: 0.83)\n",
      "Epoch: 6 (130.86s)\tTrain: (l: 0.39, a: 0.85)\tTest:  (l: 0.58, a: 0.81)\n",
      "Epoch: 7 (131.22s)\tTrain: (l: 0.38, a: 0.85)\tTest:  (l: 0.44, a: 0.82)\n",
      "Epoch: 8 (130.54s)\tTrain: (l: 0.38, a: 0.86)\tTest:  (l: 0.41, a: 0.84)\n",
      "Epoch: 9 (130.65s)\tTrain: (l: 0.38, a: 0.86)\tTest:  (l: 0.40, a: 0.84)\n",
      "Epoch: 10 (131.00s)\tTrain: (l: 0.37, a: 0.86)\tTest:  (l: 0.49, a: 0.80)\n",
      "Epoch: 11 (130.72s)\tTrain: (l: 0.37, a: 0.86)\tTest:  (l: 0.51, a: 0.79)\n",
      "Epoch: 12 (130.76s)\tTrain: (l: 0.37, a: 0.87)\tTest:  (l: 0.40, a: 0.84)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "train_loss_metric = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_acc_metric  = tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
    "test_loss_metric  = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_acc_metric   = tf.keras.metrics.BinaryAccuracy(name=\"test_accuracy\")\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .shuffle(buffer_size=10_000, seed=0)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "# 5) Training loop\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_loss_metric.reset_state()\n",
    "    train_acc_metric.reset_state()\n",
    "    test_loss_metric.reset_state()\n",
    "    test_acc_metric.reset_state()\n",
    "\n",
    "    # --- Training ---\n",
    "    for batch_x, batch_y in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(batch_x, training=True)\n",
    "            loss_value = loss_fn(batch_y, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        train_loss_metric.update_state(loss_value)\n",
    "        train_acc_metric.update_state(batch_y, logits)\n",
    "\n",
    "    # --- Validation ---\n",
    "    for batch_x, batch_y in test_dataset:\n",
    "        val_logits = model(batch_x, training=False)\n",
    "        val_loss = loss_fn(batch_y, val_logits)\n",
    "        test_loss_metric.update_state(val_loss)\n",
    "        test_acc_metric.update_state(batch_y, val_logits)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    train_loss = train_loss_metric.result().numpy()\n",
    "    train_acc  = train_acc_metric.result().numpy()\n",
    "    test_loss  = test_loss_metric.result().numpy()\n",
    "    test_acc   = test_acc_metric.result().numpy()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch} ({epoch_time:.2f}s)\\t\"\n",
    "        f\"Train: (l: {train_loss:.2f}, a: {train_acc:.2f})\\t\"\n",
    "        f\"Test:  (l: {test_loss:.2f}, a: {test_acc:.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e48d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
