{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "678928d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, losses, metrics, Sequential\n",
    "JSON_PATH = \"./data_rnn/imdb_dataset_prepared.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b929e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a1693a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data from JSON file\n",
    "print(\"Loading data...\")\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "951551b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(data[\"X_train\"], dtype=np.int32)\n",
    "y_train = np.array(data[\"y_train\"], dtype=np.float32)\n",
    "X_test  = np.array(data[\"X_test\"],  dtype=np.int32)\n",
    "y_test  = np.array(data[\"y_test\"],  dtype=np.float32)\n",
    "embeddings = np.array(data[\"embeddings\"], dtype=np.float32)\n",
    "vocab = np.array(data[\"vocab\"])\n",
    "\n",
    "X_train -= 1\n",
    "X_test -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc666457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shift → max index in X_train: 12848 min: 0\n",
      "After shift → max index in X_test:  12848 min: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"After shift → max index in X_train:\", np.max(X_train), \"min:\", np.min(X_train))\n",
    "print(\"After shift → max index in X_test: \", np.max(X_test),  \"min:\", np.min(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5dd9a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = embeddings.shape[1]\n",
    "vocab_size = embeddings.shape[0]\n",
    "sequence_length = X_train.shape[1]\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d79c6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (40000, 130)\n",
      "y_train: (40000,)\n",
      "X_test: (10000, 130)\n",
      "y_test: (10000,)\n",
      "embeddings: (12849, 50)\n",
      "vocab: (12849,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(f\"embeddings: {embeddings.shape}\")\n",
    "print(f\"vocab: {vocab.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e66110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model using Sequential API (simpler approach)\n",
    "model = Sequential([\n",
    "    layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embeddings],\n",
    "        trainable=True\n",
    "    ),\n",
    "    layers.SimpleRNN(\n",
    "        units=16,\n",
    "        activation=\"relu\",\n",
    "        return_sequences=False\n",
    "    ),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "713732b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force the model (and therefore each layer) to create its weight tensors:\n",
    "model.build(input_shape=(batch_size, sequence_length))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(),\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9515d9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "Epoch 1/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.5083 - loss: 0.7096 - val_accuracy: 0.5009 - val_loss: 0.6955\n",
      "Epoch 2/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5182 - loss: 0.6917 - val_accuracy: 0.5054 - val_loss: 0.6936\n",
      "Epoch 3/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.5235 - loss: 0.6878 - val_accuracy: 0.5101 - val_loss: 0.6905\n",
      "Epoch 4/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.5449 - loss: 0.6770 - val_accuracy: 0.6941 - val_loss: 0.6175\n",
      "Epoch 5/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.6964 - loss: 0.6085 - val_accuracy: 0.7126 - val_loss: 0.5970\n",
      "Epoch 6/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7157 - loss: 0.5872 - val_accuracy: 0.7106 - val_loss: 0.7788\n",
      "Epoch 7/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7502 - loss: 0.5484 - val_accuracy: 0.7689 - val_loss: 0.5250\n",
      "Epoch 8/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7635 - loss: 0.5223 - val_accuracy: 0.7848 - val_loss: 0.5086\n",
      "Epoch 9/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7757 - loss: 0.5039 - val_accuracy: 0.7995 - val_loss: 0.4758\n",
      "Epoch 10/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7972 - loss: 0.4750 - val_accuracy: 0.8073 - val_loss: 0.4587\n",
      "Epoch 11/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8002 - loss: 0.4613 - val_accuracy: 0.8108 - val_loss: 0.4513\n",
      "Epoch 12/12\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7960 - loss: 0.4668 - val_accuracy: 0.8149 - val_loss: 0.4751\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 12\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "\n",
    "# Simple training with model.fit()\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    shuffle=True,\n",
    "    verbose=1  # This will print progress for each epoch\n",
    ")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3487e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 (33.90s)\tTrain: (l: 0.70, a: 0.51)\tTest:  (l: 0.69, a: 0.50)\n",
      "Epoch: 2 (33.76s)\tTrain: (l: 0.69, a: 0.52)\tTest:  (l: 0.69, a: 0.50)\n",
      "Epoch: 3 (32.27s)\tTrain: (l: 0.69, a: 0.52)\tTest:  (l: 0.69, a: 0.51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-14 16:15:11.296525: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 (33.25s)\tTrain: (l: 0.69, a: 0.53)\tTest:  (l: 0.69, a: 0.51)\n",
      "Epoch: 5 (32.11s)\tTrain: (l: 0.68, a: 0.54)\tTest:  (l: 0.67, a: 0.62)\n",
      "Epoch: 6 (31.68s)\tTrain: (l: 0.66, a: 0.59)\tTest:  (l: 0.69, a: 0.53)\n",
      "Epoch: 7 (32.18s)\tTrain: (l: 0.65, a: 0.62)\tTest:  (l: 0.70, a: 0.54)\n",
      "Epoch: 8 (32.00s)\tTrain: (l: 0.62, a: 0.66)\tTest:  (l: 0.65, a: 0.60)\n",
      "Epoch: 9 (31.63s)\tTrain: (l: 0.60, a: 0.69)\tTest:  (l: 0.64, a: 0.65)\n",
      "Epoch: 10 (31.44s)\tTrain: (l: 0.57, a: 0.72)\tTest:  (l: 0.59, a: 0.71)\n",
      "Epoch: 11 (31.75s)\tTrain: (l: 0.54, a: 0.75)\tTest:  (l: 0.55, a: 0.76)\n",
      "Epoch: 12 (31.73s)\tTrain: (l: 0.52, a: 0.77)\tTest:  (l: 0.50, a: 0.77)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "train_loss_metric = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_acc_metric  = tf.keras.metrics.BinaryAccuracy(name=\"train_accuracy\")\n",
    "test_loss_metric  = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_acc_metric   = tf.keras.metrics.BinaryAccuracy(name=\"test_accuracy\")\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .shuffle(buffer_size=10_000, seed=0)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "# 5) Training loop\n",
    "epochs = 12\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Reset metrics at the start of each epoch\n",
    "    train_loss_metric.reset_state()\n",
    "    train_acc_metric.reset_state()\n",
    "    test_loss_metric.reset_state()\n",
    "    test_acc_metric.reset_state()\n",
    "\n",
    "    # --- Training ---\n",
    "    for batch_x, batch_y in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(batch_x, training=True)\n",
    "            loss_value = loss_fn(batch_y, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        train_loss_metric.update_state(loss_value)\n",
    "        train_acc_metric.update_state(batch_y, logits)\n",
    "\n",
    "    # --- Validation ---\n",
    "    for batch_x, batch_y in test_dataset:\n",
    "        val_logits = model(batch_x, training=False)\n",
    "        val_loss = loss_fn(batch_y, val_logits)\n",
    "        test_loss_metric.update_state(val_loss)\n",
    "        test_acc_metric.update_state(batch_y, val_logits)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    train_loss = train_loss_metric.result().numpy()\n",
    "    train_acc  = train_acc_metric.result().numpy()\n",
    "    test_loss  = test_loss_metric.result().numpy()\n",
    "    test_acc   = test_acc_metric.result().numpy()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: {epoch} ({epoch_time:.2f}s)\\t\"\n",
    "        f\"Train: (l: {train_loss:.2f}, a: {train_acc:.2f})\\t\"\n",
    "        f\"Test:  (l: {test_loss:.2f}, a: {test_acc:.2f})\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
