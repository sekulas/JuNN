import Base: *
import LinearAlgebra: mul!
# x * y (aka matrix multiplication)
*(A::GraphNode, x::GraphNode) = BroadcastedOperator(mul!, A, x)
forward(::BroadcastedOperator{typeof(mul!)}, A, x) = A * x
backward(::BroadcastedOperator{typeof(mul!)}, A, x, âˆ‡) = tuple(âˆ‡ * x', A' * âˆ‡)


import LinearAlgebra: diagm
# x .* y (element-wise multiplication)
Base.Broadcast.broadcasted(*, x::GraphNode, y::GraphNode) = BroadcastedOperator(*, x, y)
forward(::BroadcastedOperator{typeof(*)}, x, y) = x .* y
backward(node::BroadcastedOperator{typeof(*)}, x, y, âˆ‡) =
    # let
    #     ðŸ = ones(length(node.output))
    #     Jx = diagm(y .* ðŸ)
    #     Jy = diagm(x .* ðŸ)
    #     tuple(Jx' * âˆ‡, Jy' * âˆ‡)
    # end
( âˆ‡ .* y,  âˆ‡ .* x )

Base.Broadcast.broadcasted(-, x::GraphNode, y::GraphNode) = 
    BroadcastedOperator(-, x, y)
forward(::BroadcastedOperator{typeof(-)}, x, y) = x.- y
backward(::BroadcastedOperator{typeof(-)}, x, y, âˆ‡) = tuple(âˆ‡, -âˆ‡)



Base.Broadcast.broadcasted(+, x::GraphNode, y::GraphNode) = 
    BroadcastedOperator(+, x, y)
forward(::BroadcastedOperator{typeof(+)}, x, y) = x .+ y
backward(::BroadcastedOperator{typeof(+)}, x, y, âˆ‡) = tuple(âˆ‡, âˆ‡)



import Base: sum
sum(x::GraphNode) = BroadcastedOperator(sum, x)
forward(::BroadcastedOperator{typeof(sum)}, x) = sum(x)
backward(::BroadcastedOperator{typeof(sum)}, x, âˆ‡) = 
    let
        ðŸ = ones(length(x))
        J = ðŸ'
        tuple(J' * âˆ‡)
    end
# ( fill(âˆ‡, size(x)), )

import Statistics: mean
mean(x::GraphNode) = BroadcastedOperator(mean, x)
forward(::BroadcastedOperator{typeof(mean)}, x) =
    mean(x)
backward(::BroadcastedOperator{typeof(mean)}, x, âˆ‡) =
    let n = length(x)
        Î´ = fill(âˆ‡ / n, n)
    in
        tuple(Î´)
    end



# Potencjalnie do potegi ^-1 zamiast dzielenia w funkcji aktywacji.
Base.Broadcast.broadcasted(/, x::GraphNode, y::GraphNode) =
    BroadcastedOperator(/, x, y)
forward(::BroadcastedOperator{typeof(/)}, x, y) = x ./ y
backward(node::BroadcastedOperator{typeof(/)}, x, y::Real, âˆ‡) = 
    let
        ðŸ = ones(length(node.output))
        Jx = diagm(ðŸ ./ y)
        Jy = (-x ./ y .^2)
        tuple(Jx' * âˆ‡, Jy' * âˆ‡)
    end
    # ( âˆ‡ ./ y,
    #  -âˆ‡ .* x ./ (y .^ 2) )


import Base: max
Base.Broadcast.broadcasted(max, x::GraphNode, y::GraphNode) = 
    BroadcastedOperator(max, x, y)
forward(::BroadcastedOperator{typeof(max)}, x, y) = max.(x, y)
backward(::BroadcastedOperator{typeof(max)}, x, y, âˆ‡) = 
    let
        Jx = diagm(isless.(y, x))
        Jy = diagm(isless.(x, y))
        tuple(Jx' * âˆ‡, Jy' * âˆ‡)
    end
    # let mx = x .> y      # or `>=` to break ties differently
    #     in ( âˆ‡ .* mx, âˆ‡ .* .!mx )


sigmoid(x) = BroadcastedOperator(Ïƒ, x)
Ïƒ(x) = BroadcastedOperator(Ïƒ, x)
forward(::BroadcastedOperator{typeof(Ïƒ)}, x) = 1.0 ./ (1.0 .+ exp.(-x))
backward(node::BroadcastedOperator{typeof(Ïƒ)}, x, âˆ‡) = 
    # let
    #     y = node.output
    #     ðŸ = ones(length(y))
    #     J = diagm(y .* (1.0 .- y))
    #     tuple(J' * âˆ‡)
    # end
    let 
        y = node.output
        tuple(âˆ‡ .* (y .* (1 .- y)))
    end

Base.Broadcast.broadcasted(^, x::GraphNode, y::GraphNode) = 
    BroadcastedOperator(^, x, y)
forward(::BroadcastedOperator{typeof(^)}, x, y) = 
    x .^ y
backward(node::BroadcastedOperator{typeof(^)}, x, y, âˆ‡) = 
    let
        ðŸ = ones(length(node.output))
        Jx = diagm(y .* x .^ (y .- 1.0))
        Jy = diagm(log.(abs.(x)) .* x .^ y)
        tuple(Jx' * âˆ‡, Jy' * âˆ‡)
    end
    # ( âˆ‡ .* (y .* x .^ (y .- 1)),
    #   âˆ‡ .* (log.(abs.(x)) .* x .^ y) )

Base.Broadcast.broadcasted(exp, x::GraphNode) = 
    BroadcastedOperator(exp, x)
forward(::BroadcastedOperator{typeof(exp)}, x) = 
    exp.(x)
backward(node::BroadcastedOperator{typeof(exp)}, x, âˆ‡) = 
    let
        y = node.output
        J = diagm(y)
        tuple(J' * âˆ‡)
    end
    # ( âˆ‡ .* node.output, )

Base.Broadcast.broadcasted(log, x::GraphNode) = 
    BroadcastedOperator(log, x)
forward(::BroadcastedOperator{typeof(log)}, x) = 
    log.(x)
backward(::BroadcastedOperator{typeof(log)}, x, âˆ‡) = 
    # tuple(diagm(1.0 ./ x)' * âˆ‡)
    ( âˆ‡ ./ x, )


softmax(x::GraphNode) = BroadcastedOperator(softmax, x)
forward(::BroadcastedOperator{typeof(softmax)}, x) =
    let 
        max_x = maximum(x)
        exp_x_shifted = exp.(x .- max_x)
        sum_exp_x_shifted = sum(exp_x_shifted)
        y = exp_x_shifted ./ sum_exp_x_shifted 
    end
backward(node::BroadcastedOperator{typeof(softmax)}, x, âˆ‡) = 
    # let
    #     y = node.output
    #     J = diagm(y) .- y * y'
    #     tuple(J' * âˆ‡)
    # end
    let
        y = node.output
        Ï‰ = sum(âˆ‡ .* y)
        tuple(y .* (âˆ‡ .- Ï‰))
    end

Base.Broadcast.broadcasted(identity, x::GraphNode) = BroadcastedOperator(identity, x)
forward(::BroadcastedOperator{typeof(identity)}, x) = x
backward(::BroadcastedOperator{typeof(identity)}, x, âˆ‡) = 
    tuple(âˆ‡)


import Base: tanh
tanh(x::GraphNode) = BroadcastedOperator(tanh, x)
forward(::BroadcastedOperator{typeof(tanh)}, x) = tanh.(x)
backward(node::BroadcastedOperator{typeof(tanh)}, x, âˆ‡) =
  let
    y = node.output
    tuple((1 .- y .^ 2) .* âˆ‡)
  end

ReLU(x::GraphNode) = BroadcastedOperator(ReLU, x)
forward(::BroadcastedOperator{typeof(ReLU)}, x) = max.(0, x)
backward(node::BroadcastedOperator{typeof(ReLU)}, x, âˆ‡) =
    let
        y    = node.output
        mask = y .> 0
        tuple(mask .* âˆ‡)            
    end